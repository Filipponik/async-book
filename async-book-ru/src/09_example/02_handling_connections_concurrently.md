# Конкурентная обработка подключений

Проблема с нашим кодом на данный момент заключается в том, что `listener.incoming()` является блокирующим итератором. Исполнитель не может запускать другие футуры, пока `listener` ожидает входящих соединений, и мы не можем обрабатывать новое соединение, пока не закончим с предыдущим.

Чтобы исправить это, мы преобразуем `listener.incoming()` из блокирующего Iterator в неблокирующий Stream. Потоки похожи на итераторы, но могут использоваться асинхронно. Для получения дополнительной информации см. [главу о потоках](../05_streams/01_chapter.md) .

Давайте заменим наш блокирующий `std::net::TcpListener` на неблокирующий `async_std::net::TcpListener` и обновим наш обработчик соединения, чтобы он принимал `async_std::net::TcpStream`:

```rust,ignore
{{#include ../../examples/09_04_concurrent_tcp_server/src/main.rs:handle_connection}}
```

Асинхронная версия `TcpListener` реализует трейт `Stream` для `listener.incoming()`, это изменение дает два преимущества. Во-первых, `listener.incoming()` больше не блокирует исполнителя. Теперь исполнитель может перейти к другим ожидающим футурам, пока нет входящих TCP-соединений для обработки.

Второе преимущество заключается в том, что элементы из Stream могут обрабатываться конкурентно с помощью метода `for_each_concurrent`. Здесь мы воспользуемся этим методом для конкурентной обработки каждого входящего запроса. Нам нужно импортировать трейт `Stream` из крейта `futures`, поэтому наш Cargo.toml теперь выглядит так:

```diff
+[dependencies]
+futures = "0.3"

 [dependencies.async-std]
 version = "1.6"
 features = ["attributes"]
```

Теперь мы можем обрабатывать каждое соединение конкурентно, передавая `handle_connection` через замыкание. Замыкание становится владельцем каждого `TcpStream` и запускается, как только становится доступным новый `TcpStream`. Поскольку `handle_connection` не блокирующий, медленный запрос больше не будет препятствовать выполнению других запросов.

```rust,ignore
{{#include ../../examples/09_04_concurrent_tcp_server/src/main.rs:main_func}}
```

# Параллельное обслуживание запросов

В нашем примере до сих пор конкурентность (с использованием асинхронного кода) в основном представлялась как альтернатива параллелизму (с использованием потоков). Однако асинхронный код и потоки не исключают друг друга. В нашем примере `for_each_concurrent` обрабатывает каждое соединение, но в одном потоке. `async-std` также позволяет нам запускать задачи в отдельных потоках. Поскольку `handle_connection` является `Send` и неблокирующий, его безопасно использовать с `async_std::task::spawn`. Вот как это будет выглядеть:

```rust
{{#include ../../examples/09_05_final_tcp_server/src/main.rs:main_func}}
```

Теперь мы используем конкурентность и параллелизм для одновременной обработки нескольких запросов! Дополнительную информацию см. в [разделе о многопоточных исполнителях](../08_ecosystem/00_chapter.md#single-threading-vs-multithreading).
